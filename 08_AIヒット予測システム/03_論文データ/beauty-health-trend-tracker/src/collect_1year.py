#!/usr/bin/env python3
"""
1å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime, timedelta
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.collectors.pubmed_collector import PubMedCollector
from src.analyzers.paper_summarizer import PaperSummarizer

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

def main():
    """1å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†"""

    print("ğŸš€ 1å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹ã—ã¾ã™")
    print("="*50)

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    data_dir = Path('./data')
    (data_dir / "raw").mkdir(parents=True, exist_ok=True)
    (data_dir / "processed").mkdir(parents=True, exist_ok=True)
    (data_dir / "trends").mkdir(parents=True, exist_ok=True)

    # ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ5ã¤ã«çµã‚‹ï¼‰
    keywords = [
        "NMN anti-aging",
        "collagen supplement skin",
        "hyaluronic acid hydration",
        "CBD inflammation",
        "exosome regeneration"
    ]

    # APIè¨­å®š
    ncbi_api_key = os.getenv('NCBI_API_KEY')
    gemini_api_key = os.getenv('GEMINI_API_KEY')

    if not gemini_api_key:
        print("âŒ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    # æ—¥ä»˜ç¯„å›²ï¼ˆéå»1å¹´ï¼‰
    end_date = datetime(2024, 9, 24)
    start_date = end_date - timedelta(days=365)

    print(f"ğŸ“… æ¤œç´¢æœŸé–“: {start_date.strftime('%Y/%m/%d')} ã€œ {end_date.strftime('%Y/%m/%d')}")

    # è«–æ–‡åé›†
    collector = PubMedCollector(api_key=ncbi_api_key)
    all_papers = {}

    for idx, keyword in enumerate(keywords, 1):
        print(f"åé›†ä¸­ [{idx}/{len(keywords)}] {keyword}...", end=" ")

        # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æœ€å¤§10ä»¶åé›†
        papers = collector.search_and_fetch(
            keyword,
            max_results=10,
            start_date=start_date,
            end_date=end_date
        )

        print(f"â†’ {len(papers)}ä»¶")

        if papers:
            all_papers[keyword] = papers

    # ä¿å­˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    raw_file = data_dir / "raw" / f"papers_1year_{timestamp}.json"

    with open(raw_file, 'w', encoding='utf-8') as f:
        json.dump(all_papers, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… åé›†å®Œäº†: {sum(len(papers) for papers in all_papers.values())}ä»¶ã®è«–æ–‡")

    # AIè¦ç´„
    print("\nğŸ¤– AIè¦ç´„å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    summarizer = PaperSummarizer(api_key=gemini_api_key)
    summarized_data = {}

    for keyword, papers in all_papers.items():
        if papers:
            print(f"è¦ç´„ä¸­: {keyword} ({len(papers)}ä»¶)")
            # æœ‰åŠ¹ãªè«–æ–‡ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            valid_papers = [p for p in papers if p and isinstance(p, dict) and 'title' in p]
            if valid_papers:
                summarized = summarizer.batch_summarize(valid_papers[:5], max_papers=5)
                summarized_data[keyword] = summarized

    # è¦ç´„ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    processed_file = data_dir / "processed" / f"summarized_1year_{timestamp}.json"
    with open(processed_file, 'w', encoding='utf-8') as f:
        json.dump(summarized_data, f, ensure_ascii=False, indent=2)

    # latest_papers.jsonã¨ã—ã¦ä¿å­˜
    latest_file = data_dir / "processed" / "latest_papers.json"
    with open(latest_file, 'w', encoding='utf-8') as f:
        json.dump(summarized_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… è¦ç´„å®Œäº†")

    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    print("\nğŸ“Š ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æä¸­...")
    trend_analysis = summarizer.analyze_trends(summarized_data)

    analysis_file = data_dir / "trends" / f"analysis_1year_{timestamp}.json"
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(trend_analysis, f, ensure_ascii=False, indent=2)

    # latest_analysis.jsonã¨ã—ã¦ä¿å­˜
    latest_analysis = data_dir / "trends" / "latest_analysis.json"
    with open(latest_analysis, 'w', encoding='utf-8') as f:
        json.dump(trend_analysis, f, ensure_ascii=False, indent=2)

    print(f"âœ… åˆ†æå®Œäº†")
    print("\nğŸ‰ 1å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿åé›†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()