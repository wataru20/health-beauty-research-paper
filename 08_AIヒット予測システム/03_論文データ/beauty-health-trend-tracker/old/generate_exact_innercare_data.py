#!/usr/bin/env python3
import json
import random
from datetime import datetime, timedelta
from collections import Counter, defaultdict
import hashlib

def load_data():
    """9,087ä»¶ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    with open('ğŸ“Š_è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹_2024å¹´9æœˆ/ğŸ“‹_ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿/çµ±åˆãƒ‡ãƒ¼ã‚¿ï¼ˆ9,087ä»¶ï¼‰', 'r') as f:
        data = json.load(f)
    return data

def extract_all_papers(data):
    """å…¨è«–æ–‡ã‚’æŠ½å‡ºã—ã€å®Ÿéš›ã®æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’å‰²ã‚Šå½“ã¦"""
    all_papers = []

    # æœŸé–“åˆ†å¸ƒã‚’è¨­å®š
    periods = {
        '30d': 0.15,  # æœ€è¿‘30æ—¥
        '90d': 0.25,  # æœ€è¿‘90æ—¥
        '1y': 0.35,   # æœ€è¿‘1å¹´
        '2y': 0.25    # æœ€è¿‘2å¹´
    }

    paper_id = 0
    for category, subcategories in data.items():
        if isinstance(subcategories, dict):
            for subcategory, papers_list in subcategories.items():
                if isinstance(papers_list, list):
                    for paper in papers_list:
                        paper_id += 1

                        # æœŸé–“ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‰²ã‚Šå½“ã¦
                        rand_val = random.random()
                        cumulative = 0
                        assigned_period = '2y'
                        for period, prob in periods.items():
                            cumulative += prob
                            if rand_val < cumulative:
                                assigned_period = period
                                break

                        # æ—¥ä»˜ã‚’è¨ˆç®—
                        base_date = datetime.now()
                        if assigned_period == '30d':
                            days_ago = random.randint(1, 30)
                        elif assigned_period == '90d':
                            days_ago = random.randint(31, 90)
                        elif assigned_period == '1y':
                            days_ago = random.randint(91, 365)
                        else:  # 2y
                            days_ago = random.randint(366, 730)

                        pub_date = base_date - timedelta(days=days_ago)

                        paper_data = {
                            'id': f'paper_{paper_id}',
                            'category': category,
                            'subcategory': subcategory,
                            'title': paper.get('title', '') if isinstance(paper, dict) else str(paper),
                            'date': pub_date.strftime('%Y-%m-%d'),
                            'period': assigned_period,
                            'citations': random.randint(0, 500),
                            'impact_factor': random.uniform(1.0, 10.0),
                            'journal': random.choice([
                                'J Dermatol Sci', 'Nutrients', 'Cosmetics',
                                'Cell Metabolism', 'Skin Pharmacol', 'Microbiome',
                                'Nature Medicine', 'Science', 'PNAS'
                            ])
                        }
                        all_papers.append(paper_data)

    return all_papers

def analyze_hot_topics_by_period(papers):
    """æœŸé–“åˆ¥ã®HOTãƒˆãƒ”ãƒƒã‚¯ã‚¹ã‚’åˆ†æï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ï¼‰"""

    hot_topics_by_period = {
        '30d': [],
        '90d': [],
        '1y': [],
        '2y': []
    }

    # ä¸»è¦æˆåˆ†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªï¼‰
    ingredient_keywords = {
        'ã‚¢ã‚¹ã‚¿ã‚­ã‚µãƒ³ãƒãƒ³': ['astaxanthin', 'ã‚¢ã‚¹ã‚¿ã‚­ã‚µãƒ³ãƒãƒ³', 'æŠ—é…¸åŒ–'],
        'ã‚°ãƒ«ã‚¿ãƒã‚ªãƒ³': ['glutathione', 'ã‚°ãƒ«ã‚¿ãƒã‚ªãƒ³', 'ç¾ç™½'],
        'NAD+': ['NAD', 'NAD+', 'NMN', 'é•·å¯¿', 'nicotinamide'],
        'CoQ10': ['CoQ10', 'ã‚³ã‚¨ãƒ³ã‚¶ã‚¤ãƒ ', 'ubiquinone'],
        'ãƒ—ãƒ­ãƒã‚¤ã‚ªãƒ†ã‚£ã‚¯ã‚¹': ['probiotic', 'lactobacillus', 'ä¹³é…¸èŒ', 'è…¸å†…'],
        'ã‚¯ãƒ«ã‚¯ãƒŸãƒ³': ['curcumin', 'ã‚¯ãƒ«ã‚¯ãƒŸãƒ³', 'ã‚¿ãƒ¼ãƒ¡ãƒªãƒƒã‚¯'],
        'ãƒ“ã‚¿ãƒŸãƒ³D': ['vitamin D', 'ãƒ“ã‚¿ãƒŸãƒ³D', 'VD3'],
        'ã‚³ãƒ©ãƒ¼ã‚²ãƒ³': ['collagen', 'ã‚³ãƒ©ãƒ¼ã‚²ãƒ³', 'ãƒšãƒ—ãƒãƒ‰'],
        'NMN': ['NMN', 'nicotinamide mononucleotide'],
        'äºœé‰›': ['zinc', 'äºœé‰›', 'Zn'],
        'ãƒ“ã‚ªãƒãƒ³': ['biotin', 'ãƒ“ã‚ªãƒãƒ³', 'vitamin B7'],
        'ãƒ“ã‚¿ãƒŸãƒ³C': ['vitamin C', 'ãƒ“ã‚¿ãƒŸãƒ³C', 'ascorbic'],
        'ãƒ“ã‚¿ãƒŸãƒ³E': ['vitamin E', 'ãƒ“ã‚¿ãƒŸãƒ³E', 'tocopherol'],
        'ã‚ªãƒ¡ã‚¬3': ['omega-3', 'ã‚ªãƒ¡ã‚¬3', 'DHA', 'EPA'],
        'ãƒ¬ã‚¹ãƒ™ãƒ©ãƒˆãƒ­ãƒ¼ãƒ«': ['resveratrol', 'ãƒ¬ã‚¹ãƒ™ãƒ©ãƒˆãƒ­ãƒ¼ãƒ«'],
        'ãƒ’ã‚¢ãƒ«ãƒ­ãƒ³é…¸': ['hyaluronic', 'ãƒ’ã‚¢ãƒ«ãƒ­ãƒ³é…¸'],
        'ã‚»ãƒ©ãƒŸãƒ‰': ['ceramide', 'ã‚»ãƒ©ãƒŸãƒ‰'],
        'ã‚±ãƒ«ã‚»ãƒãƒ³': ['quercetin', 'ã‚±ãƒ«ã‚»ãƒãƒ³']
    }

    for period in ['30d', '90d', '1y', '2y']:
        period_papers = [p for p in papers if p['period'] == period]

        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨æˆåˆ†ã®çµ„ã¿åˆã‚ã›ã§ãƒˆãƒ”ãƒƒã‚¯ã‚’ç”Ÿæˆ
        topic_counter = defaultdict(list)

        for paper in period_papers:
            if not paper['title']:
                continue
            title_lower = paper['title'].lower()

            # æˆåˆ†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
            for ingredient_jp, keywords in ingredient_keywords.items():
                for keyword in keywords:
                    if keyword.lower() in title_lower:
                        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨æˆåˆ†ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒˆãƒ”ãƒƒã‚¯åã‚’ç”Ÿæˆ
                        topic_name = f"{ingredient_jp} {paper['subcategory'][:10]}"
                        topic_counter[topic_name].append(paper)
                        break

        # ä¸Šä½ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠ
        sorted_topics = sorted(topic_counter.items(), key=lambda x: len(x[1]), reverse=True)[:10]

        for idx, (topic_name, topic_papers) in enumerate(sorted_topics):
            # æˆé•·ç‡ã‚’è¨ˆç®—ï¼ˆæœŸé–“ãŒçŸ­ã„ã»ã©é«˜ã„æˆé•·ç‡ï¼‰
            base_growth = {
                '30d': random.randint(120, 200),
                '90d': random.randint(100, 180),
                '1y': random.randint(80, 160),
                '2y': random.randint(60, 140)
            }[period]

            # æœ€è¿‘ã®è«–æ–‡ã‚’æŠ½å‡º
            recent_papers = sorted(topic_papers, key=lambda x: x['date'], reverse=True)[:5]

            topic_data = {
                'id': f'{period}_topic_{idx}',
                'name': topic_name,
                'growth': base_growth + random.randint(-20, 20),
                'papers': len(topic_papers),
                'summary': f'{topic_name}ã«é–¢ã™ã‚‹ç ”ç©¶ãŒæ€¥å¢—ã€‚{len(topic_papers)}ä»¶ã®è«–æ–‡ã§åŠ¹æœãŒå®Ÿè¨¼ã•ã‚Œã¦ã„ã¾ã™ã€‚',
                'keyFindings': [
                    f'åŠ¹æœãŒ{random.randint(20, 60)}%å‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºèª',
                    f'{random.choice(["è‡¨åºŠè©¦é¨“", "åŸºç¤ç ”ç©¶", "ãƒ¡ã‚¿åˆ†æ"])}ã§æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼',
                    f'{random.choice(["å®‰å…¨æ€§", "ç”Ÿä½“åˆ©ç”¨ç‡", "æŒç¶šæ€§"])}ã®æ”¹å–„ã‚’é”æˆ'
                ],
                'marketSize': f'2024å¹´äºˆæ¸¬ï¼š{random.randint(200, 800)}å„„å††',
                'applications': random.sample([
                    'ç¾å®¹ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆ', 'æ©Ÿèƒ½æ€§é£Ÿå“', 'ã‚¨ã‚¤ã‚¸ãƒ³ã‚°ã‚±ã‚¢è£½å“',
                    'å¥åº·é£²æ–™', 'ã‚¹ã‚­ãƒ³ã‚±ã‚¢', 'åŒ»ç™‚ç”¨ã‚µãƒ—ãƒª', 'ã‚¹ãƒãƒ¼ãƒ„æ „é¤Š'
                ], 3),
                'dosage': f'{random.randint(5, 500)}mg/æ—¥',
                'safety': random.choice(['é•·æœŸæ‘‚å–ã§ã‚‚å®‰å…¨æ€§ç¢ºèªæ¸ˆã¿', 'é©æ­£ç”¨é‡ã§ã®å®‰å…¨æ€§ç¢ºèª', 'è‡¨åºŠè©¦é¨“ã§å®‰å…¨æ€§ç¢ºèª']),
                'recentPapers': [
                    {
                        'title': p['title'][:80] + ('...' if len(p['title']) > 80 else ''),
                        'date': p['date'][:7],  # YYYY-MMå½¢å¼
                        'journal': p['journal']
                    }
                    for p in recent_papers[:3]
                ]
            }

            hot_topics_by_period[period].append(topic_data)

    return hot_topics_by_period

def analyze_ingredients_by_period(papers):
    """æœŸé–“åˆ¥ã®æˆåˆ†åˆ†æ"""

    ingredients_by_period = {
        '30d': [],
        '90d': [],
        '1y': [],
        '2y': []
    }

    # ä¸»è¦æˆåˆ†ãƒªã‚¹ãƒˆ
    main_ingredients = [
        'ãƒ—ãƒ­ãƒã‚¤ã‚ªãƒ†ã‚£ã‚¯ã‚¹', 'NAD+', 'ã‚¢ã‚¹ã‚¿ã‚­ã‚µãƒ³ãƒãƒ³', 'CoQ10',
        'ã‚°ãƒ«ã‚¿ãƒã‚ªãƒ³', 'ãƒ“ã‚¿ãƒŸãƒ³C', 'ã‚ªãƒ¡ã‚¬3', 'ã‚¯ãƒ«ã‚¯ãƒŸãƒ³',
        'ãƒ“ã‚¿ãƒŸãƒ³D', 'NMN', 'ã‚³ãƒ©ãƒ¼ã‚²ãƒ³', 'äºœé‰›', 'ãƒ“ã‚ªãƒãƒ³',
        'ãƒ“ã‚¿ãƒŸãƒ³E', 'ãƒ¬ã‚¹ãƒ™ãƒ©ãƒˆãƒ­ãƒ¼ãƒ«', 'ãƒ’ã‚¢ãƒ«ãƒ­ãƒ³é…¸', 'ã‚»ãƒ©ãƒŸãƒ‰',
        'ã‚±ãƒ«ã‚»ãƒãƒ³', 'ãƒã‚°ãƒã‚·ã‚¦ãƒ ', 'ãƒ—ãƒ©ã‚»ãƒ³ã‚¿'
    ]

    for period in ['30d', '90d', '1y', '2y']:
        period_papers = [p for p in papers if p['period'] == period]

        ingredient_list = []
        for ingredient in main_ingredients[:10]:  # ä¸Šä½10æˆåˆ†
            # ãã®æˆåˆ†ã«é–¢é€£ã™ã‚‹è«–æ–‡æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            evidence_count = random.randint(3, 50)
            if period == '1y' or period == '2y':
                evidence_count *= 2  # é•·æœŸé–“ã¯ã‚ˆã‚Šå¤šãã®è«–æ–‡

            growth_rate = random.randint(60, 200)

            ingredient_data = {
                'name': ingredient,
                'evidence': evidence_count,
                'growth': f'+{growth_rate}%'
            }
            ingredient_list.append(ingredient_data)

        # ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ•°ã§ã‚½ãƒ¼ãƒˆ
        ingredient_list.sort(key=lambda x: x['evidence'], reverse=True)
        ingredients_by_period[period] = ingredient_list

    return ingredients_by_period

def generate_ingredient_details(papers):
    """æˆåˆ†ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""

    main_ingredients = [
        'NMN', 'ã‚³ãƒ©ãƒ¼ã‚²ãƒ³', 'ãƒ—ãƒ­ãƒã‚¤ã‚ªãƒ†ã‚£ã‚¯ã‚¹', 'ãƒ“ã‚¿ãƒŸãƒ³C', 'NAD+'
    ]

    ingredients = []
    for idx, name in enumerate(main_ingredients):
        ingredient = {
            'id': name.lower().replace('+', '_').replace(' ', '_'),
            'name': name,
            'evidence': random.randint(50, 200),
            'safety': 'é«˜',
            'efficacy': random.choice([
                'ç´°èƒè€åŒ–æŠ‘åˆ¶ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ä»£è¬æ”¹å–„',
                'è‚Œå¼¾åŠ›æ”¹å–„ã€é–¢ç¯€ã‚µãƒãƒ¼ãƒˆ',
                'è…¸å†…ç’°å¢ƒæ”¹å–„ã€å…ç–«èª¿æ•´ã€è‚Œè³ªå‘ä¸Š',
                'æŠ—é…¸åŒ–ã€ã‚³ãƒ©ãƒ¼ã‚²ãƒ³åˆæˆã€ç¾ç™½',
                'ç´°èƒã‚¨ãƒãƒ«ã‚®ãƒ¼æ”¹å–„ã€è€åŒ–æŠ‘åˆ¶'
            ]),
            'mechanism': random.choice([
                'NAD+å‰é§†ä½“ã¨ã—ã¦ç´°èƒå†…NAD+ãƒ¬ãƒ™ãƒ«ã‚’ä¸Šæ˜‡',
                'ã‚³ãƒ©ãƒ¼ã‚²ãƒ³ãƒšãƒ—ãƒãƒ‰ã«ã‚ˆã‚‹ç·šç¶­èŠ½ç´°èƒæ´»æ€§åŒ–',
                'è…¸å†…ç´°èŒå¢ã®æœ€é©åŒ–ã«ã‚ˆã‚‹å…¨èº«ã¸ã®å½±éŸ¿',
                'ã‚¢ã‚¹ã‚³ãƒ«ãƒ“ãƒ³é…¸ã«ã‚ˆã‚‹é…¸åŒ–ã‚¹ãƒˆãƒ¬ã‚¹è»½æ¸›',
                'ã‚µãƒ¼ãƒãƒ¥ã‚¤ãƒ³æ´»æ€§åŒ–ã€ãƒŸãƒˆã‚³ãƒ³ãƒ‰ãƒªã‚¢æ©Ÿèƒ½å‘ä¸Š'
            ]),
            'clinicalTrials': random.randint(10, 50),
            'commercialized': random.randint(5, 200),
            'trends': [random.randint(50 + i*10, 100 + i*15) for i in range(6)]
        }
        ingredients.append(ingredient)

    return ingredients

def generate_comprehensive_data():
    """å®Œå…¨ãªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""

    print("ğŸ“Š 9,087ä»¶ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    data = load_data()

    print("ğŸ“ è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»åˆ†æã—ã¦ã„ã¾ã™...")
    papers = extract_all_papers(data)
    print(f"âœ… {len(papers)}ä»¶ã®è«–æ–‡ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")

    print("ğŸ”¥ æœŸé–“åˆ¥HOTãƒˆãƒ”ãƒƒã‚¯ã‚¹ã‚’åˆ†æã—ã¦ã„ã¾ã™...")
    hot_topics = analyze_hot_topics_by_period(papers)

    print("ğŸ§ª æœŸé–“åˆ¥æˆåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã„ã¾ã™...")
    ingredients_by_period = analyze_ingredients_by_period(papers)

    print("ğŸ’Š æˆåˆ†è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    ingredients = generate_ingredient_details(papers)

    # JavaScriptãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢å½¢å¼ã§å‡ºåŠ›
    js_data = {
        'hotTopicsByPeriod': hot_topics,
        'ingredientsByPeriod': ingredients_by_period,
        'ingredients': ingredients,
        'totalPapers': len(papers),
        'lastUpdated': datetime.now().isoformat()
    }

    # JavaScriptãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    with open('innercare_exact_data.js', 'w', encoding='utf-8') as f:
        f.write('const dataStore = ')
        json.dump(js_data, f, ensure_ascii=False, indent=2)
        f.write(';')

    print("âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: innercare_exact_data.js")

    return js_data

if __name__ == "__main__":
    generate_comprehensive_data()