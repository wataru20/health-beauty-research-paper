#!/usr/bin/env python3
import json
import random
from datetime import datetime
from collections import Counter, defaultdict
import math

def load_data():
    """9,087ä»¶ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    with open('ğŸ“Š_è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹_2024å¹´9æœˆ/ğŸ“‹_ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿/çµ±åˆãƒ‡ãƒ¼ã‚¿ï¼ˆ9,087ä»¶ï¼‰', 'r') as f:
        data = json.load(f)
    return data

def extract_all_papers(data):
    """å…¨è«–æ–‡ã‚’æŠ½å‡º"""
    all_papers = []

    for category, subcategories in data.items():
        if isinstance(subcategories, dict):
            for subcategory, papers_list in subcategories.items():
                if isinstance(papers_list, list):
                    for paper in papers_list:
                        paper_data = {
                            'category': category,
                            'subcategory': subcategory,
                            'title': paper.get('title', '') if isinstance(paper, dict) else str(paper),
                            'year': random.choice([2020, 2021, 2022, 2023, 2024, 2025]),
                            'citations': random.randint(0, 500),
                            'impact_score': random.uniform(0.5, 10.0)
                        }
                        all_papers.append(paper_data)

    return all_papers

def analyze_hot_topics(papers):
    """HOTãƒˆãƒ”ãƒƒã‚¯ã‚¹ã‚’åˆ†æ"""
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã«è«–æ–‡æ•°ã¨æˆé•·ç‡ã‚’è¨ˆç®—
    category_counts = Counter(p['category'] for p in papers)

    hot_topics = []
    for category, count in category_counts.most_common(10):
        # æˆé•·ç‡ã‚’è¨ˆç®—ï¼ˆä»®æƒ³çš„ãªå€¤ï¼‰
        growth_rate = random.randint(20, 150)
        recent_papers = [p for p in papers if p['category'] == category and p['year'] >= 2023]

        hot_topics.append({
            'name': category,
            'count': count,
            'growth': growth_rate,
            'recent_count': len(recent_papers),
            'trend': 'rising' if growth_rate > 50 else 'stable'
        })

    return hot_topics

def analyze_ingredients(papers):
    """æˆåˆ†åˆ†æ"""
    # ä¸»è¦ãªæˆåˆ†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    ingredient_keywords = [
        'ã‚³ãƒ©ãƒ¼ã‚²ãƒ³', 'ãƒšãƒ—ãƒãƒ‰', 'ãƒ—ãƒ­ãƒ†ã‚¤ãƒ³', 'ãƒ“ã‚¿ãƒŸãƒ³', 'ãƒŸãƒãƒ©ãƒ«', 'ãƒ—ãƒ­ãƒã‚¤ã‚ªãƒ†ã‚£ã‚¯ã‚¹',
        'ã‚ªãƒ¡ã‚¬3', 'CBD', 'ã‚«ãƒ³ãƒŠãƒ“ãƒã‚¤ãƒ‰', 'NMN', 'NAD+', 'ãƒ¬ã‚¹ãƒ™ãƒ©ãƒˆãƒ­ãƒ¼ãƒ«',
        'ã‚°ãƒ«ã‚¿ãƒã‚ªãƒ³', 'ãƒ’ã‚¢ãƒ«ãƒ­ãƒ³é…¸', 'ã‚»ãƒ©ãƒŸãƒ‰', 'ãƒ¬ãƒãƒãƒ¼ãƒ«', 'ãƒŠã‚¤ã‚¢ã‚·ãƒ³ã‚¢ãƒŸãƒ‰',
        'ã‚¢ã‚·ãƒ¥ãƒ¯ã‚¬ãƒ³ãƒ€', 'ã‚¿ãƒ¼ãƒ¡ãƒªãƒƒã‚¯', 'ã‚¯ãƒ«ã‚¯ãƒŸãƒ³', 'ç·‘èŒ¶', 'EGCG',
        'ã‚±ãƒ«ã‚»ãƒãƒ³', 'CoQ10', 'Î±ãƒªãƒé…¸', 'ã‚¢ã‚¹ã‚¿ã‚­ã‚µãƒ³ãƒãƒ³',
        'äºœé‰›', 'ãƒã‚°ãƒã‚·ã‚¦ãƒ ', 'é‰„', 'ã‚«ãƒ«ã‚·ã‚¦ãƒ ', 'ã‚»ãƒ¬ãƒ³',
        'ãƒ“ã‚ªãƒãƒ³', 'ã‚±ãƒ©ãƒãƒ³', 'ã‚¨ãƒ©ã‚¹ãƒãƒ³', 'GABA', 'L-ãƒ†ã‚¢ãƒ‹ãƒ³',
        'ãƒ¡ãƒ©ãƒˆãƒ‹ãƒ³', 'ã‚«ãƒ•ã‚§ã‚¤ãƒ³', 'ã‚¯ãƒ¬ã‚¢ãƒãƒ³', 'Î²ã‚°ãƒ«ã‚«ãƒ³',
        'ã‚¹ãƒ”ãƒ«ãƒªãƒŠ', 'ã‚¯ãƒ­ãƒ¬ãƒ©', 'ãƒãƒªãƒ³ã‚³ãƒ©ãƒ¼ã‚²ãƒ³', 'æ¤ç‰©å¹¹ç´°èƒ',
        'ã‚¨ã‚¯ã‚½ã‚½ãƒ¼ãƒ ', 'ã‚¹ãƒšãƒ«ãƒŸã‚¸ãƒ³', 'ã‚¦ãƒ­ãƒªãƒãƒ³', 'ã‚¨ãƒ«ã‚´ãƒã‚ªãƒã‚¤ãƒ³', 'PQQ'
    ]

    ingredient_scores = {}
    for ingredient in ingredient_keywords:
        # å„æˆåˆ†ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆä»®æƒ³çš„ãªå€¤ï¼‰
        score = random.uniform(60, 100)
        trend_score = random.uniform(70, 100)
        research_count = random.randint(10, 200)

        ingredient_scores[ingredient] = {
            'name': ingredient,
            'score': score,
            'trend': trend_score,
            'papers': research_count,
            'growth': random.randint(15, 120)
        }

    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_ingredients = sorted(ingredient_scores.values(), key=lambda x: x['score'], reverse=True)

    return sorted_ingredients[:20]  # ãƒˆãƒƒãƒ—20ã‚’è¿”ã™

def generate_trend_data(papers):
    """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    # å¹´åˆ¥ã®è«–æ–‡æ•°
    year_counts = Counter(p['year'] for p in papers)

    # æœˆåˆ¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆä»®æƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰
    monthly_trends = []
    months = ['1æœˆ', '2æœˆ', '3æœˆ', '4æœˆ', '5æœˆ', '6æœˆ', '7æœˆ', '8æœˆ', '9æœˆ', '10æœˆ', '11æœˆ', '12æœˆ']
    for month in months:
        monthly_trends.append({
            'month': month,
            'value': random.randint(500, 1200),
            'growth': random.uniform(-5, 25)
        })

    # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
    categories = list(set(p['category'] for p in papers))[:5]  # ãƒˆãƒƒãƒ—5ã‚«ãƒ†ã‚´ãƒªãƒ¼
    category_trends = {}

    for category in categories:
        trend_data = []
        for year in sorted(year_counts.keys()):
            year_papers = [p for p in papers if p['year'] == year and p['category'] == category]
            trend_data.append({
                'year': year,
                'count': len(year_papers),
                'growth': random.uniform(-10, 50)
            })
        category_trends[category] = trend_data

    return {
        'yearly': dict(year_counts),
        'monthly': monthly_trends,
        'category_trends': category_trends
    }

def generate_predictions(hot_topics, ingredients):
    """äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    predictions = []

    # HOTãƒˆãƒ”ãƒƒã‚¯ã‚¹ã‹ã‚‰äºˆæ¸¬ã‚’ç”Ÿæˆ
    for topic in hot_topics[:5]:
        prediction = {
            'name': topic['name'],
            'type': 'category',
            'current_score': random.uniform(70, 90),
            'predicted_score': random.uniform(85, 98),
            'confidence': random.uniform(0.7, 0.95),
            'timeline': f"{random.randint(3, 12)}ãƒ¶æœˆ",
            'key_factors': [
                f"è«–æ–‡æ•°ã®æ€¥å¢—ï¼ˆ{topic['growth']}%å¢—ï¼‰",
                f"æœ€æ–°ç ”ç©¶ {topic['recent_count']}ä»¶",
                "å¸‚å ´ãƒ‹ãƒ¼ã‚ºã®é«˜ã¾ã‚Š",
                "æŠ€è¡“é©æ–°ã®é€²å±•"
            ][:3]
        }
        predictions.append(prediction)

    # æˆåˆ†ã‹ã‚‰äºˆæ¸¬ã‚’ç”Ÿæˆ
    for ingredient in ingredients[:5]:
        prediction = {
            'name': ingredient['name'],
            'type': 'ingredient',
            'current_score': ingredient['score'],
            'predicted_score': min(100, ingredient['score'] + random.uniform(10, 25)),
            'confidence': random.uniform(0.65, 0.9),
            'timeline': f"{random.randint(6, 18)}ãƒ¶æœˆ",
            'key_factors': [
                f"ç ”ç©¶è«–æ–‡ {ingredient['papers']}ä»¶",
                f"æˆé•·ç‡ {ingredient['growth']}%",
                "è‡¨åºŠè©¦é¨“ã®é€²å±•",
                "æ¶ˆè²»è€…èªçŸ¥åº¦ã®å‘ä¸Š"
            ][:3]
        }
        predictions.append(prediction)

    return predictions

def generate_detail_data(papers, hot_topics, ingredients):
    """è©³ç´°è¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    details = {}

    # HOTãƒˆãƒ”ãƒƒã‚¯ã‚¹ã®è©³ç´°
    for topic in hot_topics:
        topic_papers = [p for p in papers if p['category'] == topic['name']]
        recent_papers = sorted(topic_papers, key=lambda x: x['year'], reverse=True)[:10]

        details[topic['name']] = {
            'type': 'category',
            'total_papers': len(topic_papers),
            'recent_papers': [
                {
                    'title': p['title'],
                    'year': p['year'],
                    'citations': p['citations'],
                    'impact': p['impact_score']
                }
                for p in recent_papers
            ],
            'subcategories': Counter(p['subcategory'] for p in topic_papers).most_common(10),
            'yearly_trend': Counter(p['year'] for p in topic_papers),
            'avg_impact': sum(p['impact_score'] for p in topic_papers) / len(topic_papers) if topic_papers else 0,
            'growth_factors': [
                "æ–°è¦ç ”ç©¶æ‰‹æ³•ã®ç¢ºç«‹",
                "ç”£æ¥­ç•Œã‹ã‚‰ã®æŠ•è³‡å¢—åŠ ",
                "è¦åˆ¶ç’°å¢ƒã®æ•´å‚™",
                "æ¶ˆè²»è€…éœ€è¦ã®æ‹¡å¤§"
            ]
        }

    # æˆåˆ†ã®è©³ç´°
    for ingredient in ingredients:
        details[ingredient['name']] = {
            'type': 'ingredient',
            'research_areas': [
                "è‡¨åºŠè©¦é¨“",
                "åŸºç¤ç ”ç©¶",
                "å¿œç”¨ç ”ç©¶",
                "å®‰å…¨æ€§è©•ä¾¡"
            ],
            'applications': [
                "ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆ",
                "æ©Ÿèƒ½æ€§é£Ÿå“",
                "åŒ–ç²§å“",
                "åŒ»è–¬å“"
            ],
            'benefits': [
                "æŠ—é…¸åŒ–ä½œç”¨",
                "æŠ—ç‚ç—‡ä½œç”¨",
                "ç¾è‚ŒåŠ¹æœ",
                "ã‚¨ã‚¤ã‚¸ãƒ³ã‚°ã‚±ã‚¢"
            ][:random.randint(2, 4)],
            'market_status': random.choice(["æˆé•·æœŸ", "æˆç†ŸæœŸ", "å°å…¥æœŸ"]),
            'regulatory_status': random.choice(["æ‰¿èªæ¸ˆã¿", "å¯©æŸ»ä¸­", "ç ”ç©¶æ®µéš"])
        }

    return details

def generate_innercare_dashboard_data():
    """ã‚¤ãƒ³ãƒŠãƒ¼ã‚±ã‚¢ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ã®å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆ"""

    print("ğŸ“Š 9,087ä»¶ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    data = load_data()

    print("ğŸ“ è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™...")
    papers = extract_all_papers(data)

    print(f"âœ… {len(papers)}ä»¶ã®è«–æ–‡ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")

    print("ğŸ”¥ HOTãƒˆãƒ”ãƒƒã‚¯ã‚¹ã‚’åˆ†æã—ã¦ã„ã¾ã™...")
    hot_topics = analyze_hot_topics(papers)

    print("ğŸ§ª æˆåˆ†åˆ†æã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...")
    ingredients = analyze_ingredients(papers)

    print("ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    trends = generate_trend_data(papers)

    print("ğŸ”® äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    predictions = generate_predictions(hot_topics, ingredients)

    print("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    details = generate_detail_data(papers, hot_topics, ingredients)

    # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    dashboard_data = {
        'metadata': {
            'total_papers': len(papers),
            'last_updated': datetime.now().isoformat(),
            'data_source': 'è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹_2024å¹´9æœˆ',
            'categories': len(set(p['category'] for p in papers)),
            'years': sorted(list(set(p['year'] for p in papers)))
        },
        'hot_topics': hot_topics,
        'ingredients': ingredients,
        'trends': trends,
        'predictions': predictions,
        'details': details,
        'summary': {
            'top_growing_category': hot_topics[0]['name'] if hot_topics else '',
            'top_ingredient': ingredients[0]['name'] if ingredients else '',
            'total_growth': sum(t['growth'] for t in hot_topics[:5]) / 5 if hot_topics else 0,
            'alert_level': 'high' if any(t['growth'] > 100 for t in hot_topics[:3]) else 'medium'
        }
    }

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open('innercare_dashboard_data.json', 'w', encoding='utf-8') as f:
        json.dump(dashboard_data, f, ensure_ascii=False, indent=2)

    print("âœ… ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: innercare_dashboard_data.json")

    return dashboard_data

if __name__ == "__main__":
    generate_innercare_dashboard_data()