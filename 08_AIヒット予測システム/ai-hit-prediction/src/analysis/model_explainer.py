"""
ãƒ¢ãƒ‡ãƒ«èª¬æ˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
SHAPã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬æ ¹æ‹ ã‚’å¯è¦–åŒ–
"""

import shap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from typing import Optional, Dict, List, Any, Union
import logging
import json
import base64
from io import BytesIO
import warnings
warnings.filterwarnings('ignore')

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModelExplainer:
    """ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’èª¬æ˜ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model, feature_names: List[str], background_data: Optional[pd.DataFrame] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
            feature_names: ç‰¹å¾´é‡åã®ãƒªã‚¹ãƒˆ
            background_data: SHAPå€¤è¨ˆç®—ç”¨ã®èƒŒæ™¯ãƒ‡ãƒ¼ã‚¿
        """
        self.model = model
        self.feature_names = feature_names
        self.explainer = None
        self.background_data = background_data
        
        # SHAP Explainerã‚’åˆæœŸåŒ–
        self._initialize_explainer()
        
    def _initialize_explainer(self):
        """SHAP Explainerã‚’åˆæœŸåŒ–"""
        try:
            if self.background_data is not None:
                # TreeExplainerã‚’ä½¿ç”¨ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆç”¨ï¼‰
                self.explainer = shap.TreeExplainer(
                    self.model, 
                    self.background_data,
                    feature_names=self.feature_names
                )
            else:
                # èƒŒæ™¯ãƒ‡ãƒ¼ã‚¿ãªã—ã§åˆæœŸåŒ–
                self.explainer = shap.TreeExplainer(self.model)
            
            logger.info("SHAP explainer initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize SHAP explainer: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Explainerã‚’ä½¿ç”¨
            self.explainer = shap.Explainer(self.model)
    
    def explain_prediction(self, X: pd.DataFrame) -> np.ndarray:
        """
        å€‹åˆ¥äºˆæ¸¬ã®SHAPå€¤ã‚’è¨ˆç®—
        
        Args:
            X: èª¬æ˜å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            SHAPå€¤ã®é…åˆ—
        """
        if self.explainer is None:
            raise ValueError("Explainer not initialized")
        
        shap_values = self.explainer.shap_values(X)
        
        # äºŒå€¤åˆ†é¡ã®å ´åˆã€æ­£ã‚¯ãƒ©ã‚¹ã®SHAPå€¤ã‚’è¿”ã™
        if isinstance(shap_values, list) and len(shap_values) == 2:
            return shap_values[1]
        
        return shap_values
    
    def create_waterfall_plot(self, 
                            X_single: pd.DataFrame,
                            max_display: int = 10) -> Dict[str, Any]:
        """
        ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            X_single: å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒ¼ã‚¿
            max_display: è¡¨ç¤ºã™ã‚‹ç‰¹å¾´é‡ã®æœ€å¤§æ•°
            
        Returns:
            ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        # SHAPå€¤ã‚’è¨ˆç®—
        shap_values = self.explain_prediction(X_single)
        
        if len(shap_values.shape) > 1:
            shap_values = shap_values[0]
        
        # ç‰¹å¾´é‡ã¨SHAPå€¤ã‚’ãƒšã‚¢ã«ã—ã¦ã‚½ãƒ¼ãƒˆ
        feature_importance = pd.DataFrame({
            'feature': self.feature_names,
            'shap_value': shap_values,
            'feature_value': X_single.iloc[0].values
        })
        
        # çµ¶å¯¾å€¤ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’é¸æŠ
        feature_importance['abs_shap'] = abs(feature_importance['shap_value'])
        feature_importance = feature_importance.nlargest(max_display, 'abs_shap')
        feature_importance = feature_importance.sort_values('shap_value')
        
        # åŸºæº–å€¤ã¨äºˆæ¸¬å€¤
        if hasattr(self.explainer, 'expected_value'):
            if isinstance(self.explainer.expected_value, np.ndarray):
                base_value = self.explainer.expected_value[1] if len(self.explainer.expected_value) > 1 else self.explainer.expected_value[0]
            else:
                base_value = self.explainer.expected_value
        else:
            base_value = 0.5
        
        prediction_value = base_value + shap_values.sum()
        
        return {
            'features': feature_importance['feature'].tolist(),
            'shap_values': feature_importance['shap_value'].tolist(),
            'feature_values': feature_importance['feature_value'].tolist(),
            'base_value': float(base_value),
            'prediction_value': float(prediction_value)
        }
    
    def create_force_plot_data(self, X_single: pd.DataFrame) -> Dict[str, Any]:
        """
        ãƒ•ã‚©ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            X_single: å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        # SHAPå€¤ã‚’è¨ˆç®—
        shap_values = self.explain_prediction(X_single)
        
        if len(shap_values.shape) > 1:
            shap_values = shap_values[0]
        
        # åŸºæº–å€¤
        if hasattr(self.explainer, 'expected_value'):
            if isinstance(self.explainer.expected_value, np.ndarray):
                base_value = self.explainer.expected_value[1] if len(self.explainer.expected_value) > 1 else self.explainer.expected_value[0]
            else:
                base_value = self.explainer.expected_value
        else:
            base_value = 0.5
        
        # æ­£ã¨è² ã®å¯„ä¸ã‚’åˆ†é›¢
        positive_features = []
        negative_features = []
        
        for i, (feature, value) in enumerate(zip(self.feature_names, shap_values)):
            feature_data = {
                'feature': feature,
                'value': float(value),
                'feature_value': float(X_single.iloc[0, i])
            }
            
            if value > 0:
                positive_features.append(feature_data)
            else:
                negative_features.append(feature_data)
        
        # ã‚½ãƒ¼ãƒˆ
        positive_features.sort(key=lambda x: abs(x['value']), reverse=True)
        negative_features.sort(key=lambda x: abs(x['value']), reverse=True)
        
        return {
            'base_value': float(base_value),
            'prediction': float(base_value + shap_values.sum()),
            'positive_features': positive_features[:5],  # Top 5
            'negative_features': negative_features[:5]   # Top 5
        }
    
    def create_summary_plot_data(self, X: pd.DataFrame, max_features: int = 20) -> Dict[str, Any]:
        """
        ã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            X: è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒ¼ã‚¿
            max_features: è¡¨ç¤ºã™ã‚‹ç‰¹å¾´é‡ã®æœ€å¤§æ•°
            
        Returns:
            ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        # SHAPå€¤ã‚’è¨ˆç®—
        shap_values = self.explain_prediction(X)
        
        # ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆçµ¶å¯¾å€¤ã®å¹³å‡ï¼‰
        feature_importance = pd.DataFrame({
            'feature': self.feature_names,
            'importance': np.abs(shap_values).mean(axis=0)
        }).nlargest(max_features, 'importance')
        
        # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        selected_indices = [self.feature_names.index(f) for f in feature_importance['feature']]
        
        # å„ç‰¹å¾´é‡ã®SHAPå€¤ã¨å®Ÿéš›ã®å€¤
        plot_data = []
        for idx in selected_indices:
            feature_name = self.feature_names[idx]
            for i in range(len(X)):
                plot_data.append({
                    'feature': feature_name,
                    'shap_value': float(shap_values[i, idx]),
                    'feature_value': float(X.iloc[i, idx]),
                    'importance': float(feature_importance[feature_importance['feature'] == feature_name]['importance'].iloc[0])
                })
        
        return {
            'data': plot_data,
            'features': feature_importance['feature'].tolist(),
            'importances': feature_importance['importance'].tolist()
        }
    
    def create_dependence_plot_data(self, 
                                  X: pd.DataFrame,
                                  feature_name: str,
                                  interaction_feature: Optional[str] = None) -> Dict[str, Any]:
        """
        ä¾å­˜ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            X: ãƒ‡ãƒ¼ã‚¿
            feature_name: å¯¾è±¡ç‰¹å¾´é‡å
            interaction_feature: ç›¸äº’ä½œç”¨ã‚’è¦‹ã‚‹ç‰¹å¾´é‡å
            
        Returns:
            ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        if feature_name not in self.feature_names:
            raise ValueError(f"Feature '{feature_name}' not found")
        
        # SHAPå€¤ã‚’è¨ˆç®—
        shap_values = self.explain_prediction(X)
        
        # ç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        feature_idx = self.feature_names.index(feature_name)
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        plot_data = {
            'feature_values': X.iloc[:, feature_idx].tolist(),
            'shap_values': shap_values[:, feature_idx].tolist()
        }
        
        # ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ãŒã‚ã‚‹å ´åˆ
        if interaction_feature and interaction_feature in self.feature_names:
            interaction_idx = self.feature_names.index(interaction_feature)
            plot_data['interaction_values'] = X.iloc[:, interaction_idx].tolist()
            plot_data['interaction_feature'] = interaction_feature
        
        return plot_data
    
    def get_feature_importance_ranking(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        ç‰¹å¾´é‡ã®é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—
        
        Args:
            X: ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®DataFrame
        """
        # SHAPå€¤ã‚’è¨ˆç®—
        shap_values = self.explain_prediction(X)
        
        # å„ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¨ˆç®—
        importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance_mean': np.abs(shap_values).mean(axis=0),
            'importance_std': np.abs(shap_values).std(axis=0),
            'positive_impact': (shap_values > 0).mean(axis=0),
            'negative_impact': (shap_values < 0).mean(axis=0)
        })
        
        # ã‚½ãƒ¼ãƒˆ
        importance_df = importance_df.sort_values('importance_mean', ascending=False)
        importance_df['rank'] = range(1, len(importance_df) + 1)
        
        return importance_df
    
    def generate_explanation_report(self, 
                                   X_single: pd.DataFrame,
                                   product_name: str = "Product") -> Dict[str, Any]:
        """
        äºˆæ¸¬ã®è©³ç´°ãªèª¬æ˜ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            X_single: å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒ¼ã‚¿
            product_name: è£½å“å
            
        Returns:
            èª¬æ˜ãƒ¬ãƒãƒ¼ãƒˆã®è¾æ›¸
        """
        # äºˆæ¸¬å€¤ã‚’å–å¾—
        prediction_proba = self.model.predict_proba(X_single)[0, 1]
        
        # SHAPå€¤ã‚’è¨ˆç®—
        shap_values = self.explain_prediction(X_single)
        if len(shap_values.shape) > 1:
            shap_values = shap_values[0]
        
        # ãƒˆãƒƒãƒ—è¦å› ã‚’æŠ½å‡º
        feature_impact = pd.DataFrame({
            'feature': self.feature_names,
            'shap_value': shap_values,
            'abs_shap': abs(shap_values)
        }).nlargest(10, 'abs_shap')
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–è¦å› ã‚’åˆ†é›¢
        positive_factors = feature_impact[feature_impact['shap_value'] > 0].to_dict('records')
        negative_factors = feature_impact[feature_impact['shap_value'] < 0].to_dict('records')
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®š
        if prediction_proba >= 0.7:
            risk_level = "Low Risk / High Potential"
            risk_color = "success"
        elif prediction_proba >= 0.4:
            risk_level = "Medium Risk / Medium Potential"
            risk_color = "warning"
        else:
            risk_level = "High Risk / Low Potential"
            risk_color = "danger"
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = {
            'product_name': product_name,
            'prediction': {
                'probability': float(prediction_proba),
                'percentage': f"{prediction_proba * 100:.1f}%",
                'risk_level': risk_level,
                'risk_color': risk_color
            },
            'key_factors': {
                'positive': positive_factors,
                'negative': negative_factors,
                'top_positive': positive_factors[0] if positive_factors else None,
                'top_negative': negative_factors[0] if negative_factors else None
            },
            'recommendations': self._generate_recommendations(feature_impact, prediction_proba)
        }
        
        return report
    
    def _generate_recommendations(self, 
                                feature_impact: pd.DataFrame,
                                prediction_proba: float) -> List[str]:
        """
        æ”¹å–„æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
        
        Args:
            feature_impact: ç‰¹å¾´é‡ã®å½±éŸ¿åº¦
            prediction_proba: äºˆæ¸¬ç¢ºç‡
            
        Returns:
            æ¨å¥¨äº‹é …ã®ãƒªã‚¹ãƒˆ
        """
        recommendations = []
        
        # ãƒã‚¬ãƒ†ã‚£ãƒ–è¦å› ã«åŸºã¥ãæ¨å¥¨
        negative_factors = feature_impact[feature_impact['shap_value'] < 0]
        
        for _, row in negative_factors.iterrows():
            feature = row['feature']
            
            if 'buzz' in feature.lower() or 'news' in feature.lower():
                recommendations.append("ğŸ“° ãƒ¡ãƒ‡ã‚£ã‚¢éœ²å‡ºã‚’å¢—ã‚„ã™ãŸã‚ã®PRæˆ¦ç•¥ã‚’å¼·åŒ–")
            elif 'academic' in feature.lower() or 'paper' in feature.lower():
                recommendations.append("ğŸ”¬ ç§‘å­¦çš„æ ¹æ‹ ã®å¼·åŒ–ã¨ç ”ç©¶æˆæœã®æ´»ç”¨")
            elif 'competitor' in feature.lower():
                recommendations.append("ğŸ¯ ç«¶åˆå·®åˆ¥åŒ–æˆ¦ç•¥ã®æ˜ç¢ºåŒ–")
            elif 'price' in feature.lower():
                recommendations.append("ğŸ’° ä¾¡æ ¼æˆ¦ç•¥ã®è¦‹ç›´ã—ã¨ä¾¡å€¤ææ¡ˆã®å¼·åŒ–")
            elif 'novelty' in feature.lower() or 'innovation' in feature.lower():
                recommendations.append("ğŸ’¡ è£½å“ã®ç‹¬è‡ªæ€§ãƒ»æ–°è¦æ€§ã®ã‚¢ãƒ”ãƒ¼ãƒ«å¼·åŒ–")
        
        # äºˆæ¸¬ç¢ºç‡ã«åŸºã¥ãä¸€èˆ¬çš„ãªæ¨å¥¨
        if prediction_proba < 0.5:
            recommendations.append("âš ï¸ å…¨ä½“çš„ãªè£½å“æˆ¦ç•¥ã®è¦‹ç›´ã—ã‚’æ¨å¥¨")
        elif prediction_proba < 0.7:
            recommendations.append("ğŸ“ˆ ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ–½ç­–ã®å¼·åŒ–ã§æˆåŠŸç¢ºç‡å‘ä¸Šã®ä½™åœ°ã‚ã‚Š")
        else:
            recommendations.append("âœ… ç¾åœ¨ã®æˆ¦ç•¥ã‚’ç¶­æŒã—ã¤ã¤ã€ç´°éƒ¨ã®æœ€é©åŒ–ã‚’ç¶™ç¶š")
        
        # é‡è¤‡ã‚’å‰Šé™¤ã—ã¦æœ€å¤§5ã¤ã¾ã§
        return list(dict.fromkeys(recommendations))[:5]


class InteractivePlotter:
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def create_waterfall_plot(waterfall_data: Dict[str, Any]) -> go.Figure:
        """
        Plotlyã§ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
        
        Args:
            waterfall_data: ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«ãƒ—ãƒ­ãƒƒãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Plotlyãƒ•ã‚£ã‚®ãƒ¥ã‚¢
        """
        features = waterfall_data['features']
        values = waterfall_data['shap_values']
        
        # ç´¯ç©å€¤ã‚’è¨ˆç®—
        cumulative = [waterfall_data['base_value']]
        for v in values:
            cumulative.append(cumulative[-1] + v)
        
        # ã‚«ãƒ©ãƒ¼è¨­å®š
        colors = ['lightgray'] + ['red' if v < 0 else 'green' for v in values] + ['blue']
        
        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig = go.Figure(go.Waterfall(
            name="SHAP",
            orientation="v",
            measure=["relative"] * len(values) + ["total"],
            x=['Base'] + features + ['Prediction'],
            y=[waterfall_data['base_value']] + values + [waterfall_data['prediction_value']],
            connector={"line": {"color": "rgb(63, 63, 63)"}},
            decreasing={"marker": {"color": "rgba(219, 64, 82, 0.7)"}},
            increasing={"marker": {"color": "rgba(50, 171, 96, 0.7)"}},
            totals={"marker": {"color": "rgba(55, 128, 191, 0.7)"}}
        ))
        
        fig.update_layout(
            title="äºˆæ¸¬ã¸ã®å„ç‰¹å¾´é‡ã®å¯„ä¸åº¦",
            xaxis_title="ç‰¹å¾´é‡",
            yaxis_title="äºˆæ¸¬ç¢ºç‡",
            showlegend=False,
            height=500
        )
        
        return fig
    
    @staticmethod
    def create_force_plot(force_data: Dict[str, Any]) -> go.Figure:
        """
        Plotlyã§ãƒ•ã‚©ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
        
        Args:
            force_data: ãƒ•ã‚©ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Plotlyãƒ•ã‚£ã‚®ãƒ¥ã‚¢
        """
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        positive_values = [f['value'] for f in force_data['positive_features']]
        positive_labels = [f"{f['feature']}: {f['value']:.3f}" for f in force_data['positive_features']]
        
        negative_values = [f['value'] for f in force_data['negative_features']]
        negative_labels = [f"{f['feature']}: {f['value']:.3f}" for f in force_data['negative_features']]
        
        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig = go.Figure()
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–è¦å› 
        if positive_values:
            fig.add_trace(go.Bar(
                y=positive_labels,
                x=positive_values,
                orientation='h',
                name='Positive',
                marker_color='rgba(50, 171, 96, 0.7)'
            ))
        
        # ãƒã‚¬ãƒ†ã‚£ãƒ–è¦å› 
        if negative_values:
            fig.add_trace(go.Bar(
                y=negative_labels,
                x=negative_values,
                orientation='h',
                name='Negative',
                marker_color='rgba(219, 64, 82, 0.7)'
            ))
        
        fig.update_layout(
            title=f"äºˆæ¸¬å€¤: {force_data['prediction']:.3f} (åŸºæº–å€¤: {force_data['base_value']:.3f})",
            xaxis_title="SHAPå€¤",
            yaxis_title="ç‰¹å¾´é‡",
            barmode='overlay',
            height=400
        )
        
        return fig
    
    @staticmethod
    def create_summary_plot(summary_data: Dict[str, Any]) -> go.Figure:
        """
        Plotlyã§ã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
        
        Args:
            summary_data: ã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Plotlyãƒ•ã‚£ã‚®ãƒ¥ã‚¢
        """
        df = pd.DataFrame(summary_data['data'])
        
        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig = px.scatter(
            df, 
            x='shap_value', 
            y='feature',
            color='feature_value',
            color_continuous_scale='RdBu',
            labels={'shap_value': 'SHAPå€¤', 'feature': 'ç‰¹å¾´é‡', 'feature_value': 'ç‰¹å¾´é‡ã®å€¤'},
            title='ç‰¹å¾´é‡ã®é‡è¦åº¦ã¨å½±éŸ¿'
        )
        
        fig.update_layout(
            height=600,
            yaxis={'categoryorder': 'total ascending'}
        )
        
        return fig


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–¢æ•°"""
    import sys
    import os
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    
    from src.models.basic_model import HitPredictionModel, generate_dummy_data
    
    logger.info("=== Model Explainer Test ===")
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    data, labels = generate_dummy_data(100)
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = HitPredictionModel()
    X = model.prepare_features(data)
    model.train(X, labels, validate=False)
    
    # ExplaineråˆæœŸåŒ–
    explainer = ModelExplainer(
        model.model,
        feature_names=X.columns.tolist(),
        background_data=X[:50]  # èƒŒæ™¯ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åŠåˆ†ã‚’ä½¿ç”¨
    )
    
    # å˜ä¸€äºˆæ¸¬ã®èª¬æ˜
    X_test = X.iloc[[0]]
    
    logger.info("\n1. Generating waterfall plot data...")
    waterfall_data = explainer.create_waterfall_plot(X_test)
    logger.info(f"   Base value: {waterfall_data['base_value']:.3f}")
    logger.info(f"   Prediction: {waterfall_data['prediction_value']:.3f}")
    
    logger.info("\n2. Generating force plot data...")
    force_data = explainer.create_force_plot_data(X_test)
    logger.info(f"   Top positive factor: {force_data['positive_features'][0] if force_data['positive_features'] else 'None'}")
    logger.info(f"   Top negative factor: {force_data['negative_features'][0] if force_data['negative_features'] else 'None'}")
    
    logger.info("\n3. Generating summary plot data...")
    summary_data = explainer.create_summary_plot_data(X[:20])
    logger.info(f"   Analyzed {len(summary_data['features'])} features")
    
    logger.info("\n4. Generating explanation report...")
    report = explainer.generate_explanation_report(X_test, "Test Product")
    logger.info(f"   Prediction: {report['prediction']['percentage']}")
    logger.info(f"   Risk Level: {report['prediction']['risk_level']}")
    logger.info(f"   Recommendations: {len(report['recommendations'])} items")
    
    logger.info("\nâœ… Model explainer test completed!")
    
    return explainer


if __name__ == "__main__":
    main()