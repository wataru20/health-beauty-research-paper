#!/usr/bin/env python3
"""
éŸ“å›½â†’æ—¥æœ¬ãƒ’ãƒƒãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨APIå®Ÿè£…
"""

import json
import pickle
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from flask import Flask, request, jsonify, render_template_string
from flask_cors import CORS
import logging
import warnings
warnings.filterwarnings('ignore')

class HitPredictor:
    def __init__(self):
        self.model = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2
        )
        self.scaler = StandardScaler()
        self.feature_names = []
        self.feature_importance = {}
        self.is_trained = False
        
    def load_training_data(self, filepath='training_data.json'):
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            df = pd.DataFrame(data['training_data'])
            
            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†é›¢
            feature_columns = [col for col in df.columns if col not in ['product_name', 'category', 'hit_in_japan']]
            X = df[feature_columns]
            y = df['hit_in_japan']
            
            self.feature_names = feature_columns
            return X, y, df
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None, None
    
    def train(self, X, y):
        """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–
            X_scaled = self.scaler.fit_transform(X)
            
            # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.2, random_state=42, stratify=y
            )
            
            # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            self.model.fit(X_train, y_train)
            
            # è©•ä¾¡
            train_score = self.model.score(X_train, y_train)
            test_score = self.model.score(X_test, y_test)
            
            # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            cv_scores = cross_val_score(self.model, X_scaled, y, cv=5)
            
            # ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
            self.feature_importance = dict(zip(self.feature_names, self.model.feature_importances_))
            
            self.is_trained = True
            
            print(f"è¨“ç·´å®Œäº†:")
            print(f"  è¨“ç·´ã‚¹ã‚³ã‚¢: {train_score:.3f}")
            print(f"  ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {test_score:.3f}")
            print(f"  CVå¹³å‡ã‚¹ã‚³ã‚¢: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
            print(f"  é‡è¦ãªç‰¹å¾´é‡ãƒˆãƒƒãƒ—5:")
            sorted_features = sorted(self.feature_importance.items(), key=lambda x: x[1], reverse=True)
            for name, importance in sorted_features[:5]:
                print(f"    {name}: {importance:.3f}")
            
            return {
                'train_score': train_score,
                'test_score': test_score,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'feature_importance': self.feature_importance
            }
            
        except Exception as e:
            print(f"è¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def predict(self, features):
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
        if not self.is_trained:
            return {'error': 'ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“'}
        
        try:
            # ç‰¹å¾´é‡ã‚’ DataFrame ã«å¤‰æ›
            if isinstance(features, dict):
                features_df = pd.DataFrame([features])
            else:
                features_df = pd.DataFrame(features)
            
            # ç‰¹å¾´é‡ã®é †åºã‚’åˆã‚ã›ã‚‹
            features_df = features_df[self.feature_names]
            
            # æ¨™æº–åŒ–
            features_scaled = self.scaler.transform(features_df)
            
            # äºˆæ¸¬
            hit_probability = self.model.predict_proba(features_scaled)[0][1]
            prediction = self.model.predict(features_scaled)[0]
            
            # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆäºˆæ¸¬ç¢ºç‡ã‹ã‚‰ï¼‰
            confidence = max(hit_probability, 1 - hit_probability)
            
            # ãƒªã‚¹ã‚¯è¦å› ã¨æˆåŠŸè¦å› ã‚’ç‰¹å®š
            risk_factors, success_drivers = self._analyze_factors(features)
            
            return {
                'hit_probability': float(hit_probability * 100),
                'prediction': int(prediction),
                'confidence_score': float(confidence * 10),
                'risk_factors': risk_factors,
                'success_drivers': success_drivers,
                'feature_contributions': self._get_feature_contributions(features)
            }
            
        except Exception as e:
            return {'error': f'äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}'}
    
    def _analyze_factors(self, features):
        """ãƒªã‚¹ã‚¯è¦å› ã¨æˆåŠŸè¦å› ã‚’åˆ†æ"""
        risk_factors = []
        success_drivers = []
        
        # æ–‡åŒ–çš„å—å®¹æ€§ãƒã‚§ãƒƒã‚¯
        if features.get('cultural_acceptance_score', 5) < 5:
            risk_factors.append('æ—¥æœ¬æ–‡åŒ–é©åˆåº¦ãŒä½ã„')
        elif features.get('cultural_acceptance_score', 5) > 7:
            success_drivers.append('æ—¥æœ¬æ–‡åŒ–é©åˆåº¦ãŒé«˜ã„')
        
        # ã‚¿ãƒ–ãƒ¼ãƒªã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯
        if features.get('cultural_taboo_risk', 5) > 6:
            risk_factors.append('æ–‡åŒ–çš„ã‚¿ãƒ–ãƒ¼ãƒªã‚¹ã‚¯ãŒé«˜ã„')
        
        # éŸ“å›½ã§ã®äººæ°—åº¦ãƒã‚§ãƒƒã‚¯
        if features.get('kr_total_views', 0) < 300:
            risk_factors.append('éŸ“å›½ã§ã®æ³¨ç›®åº¦ãŒä½ã„')
        elif features.get('kr_total_views', 0) > 500:
            success_drivers.append('éŸ“å›½ã§é«˜ã„æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã‚‹')
        
        # æ—¥æœ¬ã§ã®æ—©æœŸæ¡ç”¨ãƒã‚§ãƒƒã‚¯
        if features.get('jp_youtuber_mention_count', 0) > 20:
            success_drivers.append('æ—¥æœ¬YouTuberã«æ—¢ã«å–ã‚Šä¸Šã’ã‚‰ã‚Œã¦ã„ã‚‹')
        elif features.get('jp_youtuber_mention_count', 0) < 5:
            risk_factors.append('æ—¥æœ¬ã§ã®èªçŸ¥ãŒé™å®šçš„')
        
        # ä¾¡æ ¼ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£
        if features.get('price_accessibility', 5) < 4:
            risk_factors.append('ä¾¡æ ¼ãŒé«˜ãä¸€èˆ¬æ¶ˆè²»è€…ã«ã¯æ‰‹ãŒå±Šãã«ãã„')
        elif features.get('price_accessibility', 5) > 7:
            success_drivers.append('æ‰‹é ƒãªä¾¡æ ¼è¨­å®š')
        
        # å…¥æ‰‹ã—ã‚„ã™ã•
        if features.get('availability_score', 5) < 4:
            risk_factors.append('å…¥æ‰‹ãŒå›°é›£')
        
        # è¦åˆ¶éšœå£
        if features.get('regulatory_barrier', 5) > 6:
            risk_factors.append('è¦åˆ¶ä¸Šã®éšœå£ãŒé«˜ã„')
        
        return risk_factors[:3], success_drivers[:3]  # æœ€å¤§3ã¤ãšã¤
    
    def _get_feature_contributions(self, features):
        """ç‰¹å¾´é‡ã®è²¢çŒ®åº¦ã‚’è¨ˆç®—"""
        contributions = {}
        for feature_name in self.feature_names:
            value = features.get(feature_name, 0)
            importance = self.feature_importance.get(feature_name, 0)
            # æ­£è¦åŒ–ã•ã‚ŒãŸå€¤ Ã— é‡è¦åº¦ã§è²¢çŒ®åº¦ã‚’è¨ˆç®—
            normalized_value = min(max(value / 10.0, 0), 1)  # 0-1ã«æ­£è¦åŒ–
            contributions[feature_name] = float(normalized_value * importance)
        return contributions
    
    def save_model(self, filepath='trained_model.pkl'):
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        try:
            model_data = {
                'model': self.model,
                'scaler': self.scaler,
                'feature_names': self.feature_names,
                'feature_importance': self.feature_importance,
                'is_trained': self.is_trained
            }
            with open(filepath, 'wb') as f:
                pickle.dump(model_data, f)
            print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ {filepath} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def load_model(self, filepath='trained_model.pkl'):
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.feature_names = model_data['feature_names']
            self.feature_importance = model_data['feature_importance']
            self.is_trained = model_data['is_trained']
            
            print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ {filepath} ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except Exception as e:
            print(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# Flask APIã®è¨­å®š
app = Flask(__name__)
CORS(app)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«äºˆæ¸¬å™¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
predictor = HitPredictor()

@app.route('/')
def home():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    return render_template_string("""
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <title>éŸ“å›½â†’æ—¥æœ¬ãƒ’ãƒƒãƒˆäºˆæ¸¬API</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }
            .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
            h1 { color: #333; text-align: center; }
            .endpoint { background: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0; }
            .method { background: #007bff; color: white; padding: 3px 8px; border-radius: 3px; font-size: 12px; }
            code { background: #e9ecef; padding: 2px 5px; border-radius: 3px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ”® éŸ“å›½â†’æ—¥æœ¬ãƒ’ãƒƒãƒˆäºˆæ¸¬API</h1>
            <p>ç¾å®¹ãƒ»å¥åº·é–¢é€£å•†å“ã®æ—¥æœ¬å¸‚å ´ã§ã®ãƒ’ãƒƒãƒˆå¯èƒ½æ€§ã‚’äºˆæ¸¬ã™ã‚‹APIã§ã™ã€‚</p>
            
            <h2>åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:</h2>
            
            <div class="endpoint">
                <h3><span class="method">POST</span> /predict</h3>
                <p>å•†å“ã®ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ—¥æœ¬ã§ã®ãƒ’ãƒƒãƒˆç¢ºç‡ã‚’äºˆæ¸¬</p>
                <p><strong>å…¥åŠ›:</strong> JSONå½¢å¼ã®ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿</p>
                <p><strong>å‡ºåŠ›:</strong> ãƒ’ãƒƒãƒˆç¢ºç‡ã€ä¿¡é ¼åº¦ã€ãƒªã‚¹ã‚¯è¦å› ã€æˆåŠŸè¦å› </p>
            </div>
            
            <div class="endpoint">
                <h3><span class="method">GET</span> /model_info</h3>
                <p>ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã¨ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—</p>
            </div>
            
            <div class="endpoint">
                <h3><span class="method">POST</span> /retrain</h3>
                <p>ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´ï¼ˆé–‹ç™ºç”¨ï¼‰</p>
            </div>
            
            <h2>ä½¿ç”¨ä¾‹:</h2>
            <pre><code>curl -X POST http://localhost:5000/predict \\
  -H "Content-Type: application/json" \\
  -d '{
    "kr_youtuber_mention_count": 45,
    "kr_total_views": 850,
    "cultural_acceptance_score": 9,
    "price_accessibility": 7,
    ...
  }'</code></pre>
        </div>
    </body>
    </html>
    """)

@app.route('/predict', methods=['POST'])
def predict_hit():
    """ãƒ’ãƒƒãƒˆäºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™'}), 400
        
        result = predictor.predict(data)
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/model_info', methods=['GET'])
def model_info():
    """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    if not predictor.is_trained:
        return jsonify({'error': 'ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 400
    
    return jsonify({
        'is_trained': predictor.is_trained,
        'feature_names': predictor.feature_names,
        'feature_importance': predictor.feature_importance,
        'top_features': dict(sorted(predictor.feature_importance.items(), key=lambda x: x[1], reverse=True)[:10])
    })

@app.route('/retrain', methods=['POST'])
def retrain_model():
    """ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        X, y, df = predictor.load_training_data()
        if X is None:
            return jsonify({'error': 'è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—'}), 500
        
        results = predictor.train(X, y)
        if results:
            predictor.save_model()
            return jsonify({
                'message': 'å†è¨“ç·´å®Œäº†',
                'results': results
            })
        else:
            return jsonify({'error': 'è¨“ç·´ã«å¤±æ•—'}), 500
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("éŸ“å›½â†’æ—¥æœ¬ãƒ’ãƒƒãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    X, y, df = predictor.load_training_data()
    if X is None:
        print("ã‚¨ãƒ©ãƒ¼: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(df)} å•†å“, {len(predictor.feature_names)} ç‰¹å¾´é‡")
    print(f"æˆåŠŸäº‹ä¾‹: {sum(y)} å•†å“, å¤±æ•—äº‹ä¾‹: {len(y) - sum(y)} å•†å“")
    
    # æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã‹æ–°è¦è¨“ç·´
    try:
        predictor.load_model()
        print("æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except:
        print("æ–°è¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        results = predictor.train(X, y)
        if results:
            predictor.save_model()
        else:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
    
    print("\n=== ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº† ===")
    print("APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™...")
    print("ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5000 ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãã ã•ã„")
    
    # APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•
    app.run(debug=False, host='0.0.0.0', port=5000)

if __name__ == '__main__':
    main()